#!/usr/bin/python3
# btrfs-snapshot-sender Copyright (c) 2014 Stuart Pook (http://www.pook.it/)
# Use btrfs send to backup from existing snapshots. Can do incremental backups.
#
# This program is free software: you can redistribute it and/or modify it under
# the terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
# FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

# To use this program create a file on the backup medium called
# "btrfs-snapshot-sender.tag" containing a short unique tag for the
# backups on this medium, and a file
# "/etc/local/btrfs-snapshot-sender.conf" containing:
'''
[DEFAULT]
SnapshotRoot = /disks/data/snapshots
[music]
[photos]
'''
# This will find the most recent snapshot under /disks/data/snapshots/{music,photos}
# and back them up using btrfs send and gpg.
# You will have to read the code to find the other options that can go in the configuration file.

# Watch out for https://patchwork.kernel.org/patch/3258971/

import os
import sys
import subprocess
import hashlib
import optparse
import configparser
import pipes
import errno
import fnmatch
import shutil
import multiprocessing
import functools

def myname():
	return os.path.basename(sys.argv[0])
	
def verbose(options, *args):
	if options.verbose:
		print(myname() + ":", *args, file=sys.stderr)
	
def fatal(options, *args):
	print(myname() + ": fatal error:", *args, file=sys.stderr)
	sys.exit(7)
	
def flush(f):
	f.flush()
	os.fsync(f.fileno())
	
def rename(src, dst, options):
	verbose(options, "mv", src, dst)
	os.rename(src, dst)

def run_coroutines(coroutines, options):
	verbose(options, "start")
	for coroutine in coroutines:
		next(coroutine)
	verbose(options, "wait for")
	r = []
	for coroutine in coroutines:
		r.append(next(coroutine))
	return r

def scan_snapshot_directory(directory, section, options):
	glob = section.get("SnapshotGlob", "[!.]*[!#~]")
	latest = None
	for entry in os.listdir(directory):
		if fnmatch.fnmatch(entry, glob) and (not latest or entry > latest):
			latest = entry

	if not latest:
		fatal(options, "no snapshots in", directory)
	return latest
	
def print_command(cmd, options):
	verbose(options, "run", " ".join(pipes.quote(c) for c in cmd))
	return cmd
	
def put_result(f, q):
	q.put(f())

def start_encryption(input, section, options):
	gpg_command = section.get("Filter", None)
	if not gpg_command:
		return input, None
	gpg = gpg_command.split()
	for i in range(100):
		extra = section.get("FilterArgument%02d" % i, None)
		if extra is not None:
			gpg.append(extra)
	print_command(gpg, options)
	return subprocess.Popen(gpg, stdout=subprocess.PIPE, stdin=input.stdout), gpg
	
def get_btrfs_command(section, options):
	return section.get("BtrfsSend", "sudo btrfs send").split()
	
def start_full_backup(section, snapshot, options):
	cmd = get_btrfs_command(section, options)
	if options.btrfs_verbose:
		cmd.append("-v")
	cmd.append(snapshot)
	print_command(cmd, options)
	return subprocess.Popen(cmd, stdout=subprocess.PIPE), cmd
	
def start_incremental_backup(section, latest_fname, in_use_fname, options):
	cmd = get_btrfs_command(section, options)
	if options.btrfs_verbose:
		cmd.append("-v")
	cmd.extend(["-p", in_use_fname])
	cmd.append(latest_fname)
	print_command(cmd, options)
	return subprocess.Popen(cmd, stdout=subprocess.PIPE), cmd
	
def read_write_md5(buf, input, output, options):
	dumpmd5 = hashlib.md5()
	while True:
		output.write(buf)
		dumpmd5.update(buf)
		buf = input.read(options.blocking)
		if len(buf) == 0:
			break
	output.flush()
	return dumpmd5.hexdigest()
	
def wait_command(p, cmd, options):
	if p.wait():
		fatal(options, "failed:", " ".join(pipes.quote(c) for c in cmd))
		
def set_filemode(file, section, options):
	u = section.get("OutputFileMode", None)
	if u:
		v = int(u, 8)
		verbose(options, "fchmod", "0%o" % v, file.fileno())
		os.fchmod(file.fileno(), v)
		
def get_directory(section, options):
	snapshots_key = "Snapshots"
	directory = section.get(snapshots_key, None)
	if directory:
		return directory
	snapshotroot_key = "SnapshotRoot"
	root = section.get(snapshotroot_key, None)
	if root is None:
		fatal(options, "a", snapshots_key, "or", snapshotroot_key, "attribute is required for section", section.name)
	return os.path.join(root, section.name)

def possible_unlink(output_name, options):
	try:
		os.unlink(output_name)
		verbose(options, "removed",  output_name)
	except FileNotFoundError as ex:
		if ex.errno != errno.ENOENT:
			raise
		
def find_latest_snapshot(section, directory, options):
	glob = section.get("SnapshotGlob", "[!.]*[!#~]")
	latest = None
	for entry in os.listdir(directory):
		if fnmatch.fnmatch(entry, glob):
			if not latest or entry > latest:
				latest = entry
	if not latest:
		fatal(options, "no snapshots in", directory)
	return latest
		
def read_snapshots(section, options):
	snap = None
	fname = section.name + section.get("SnapListSuffix", options.snapshots_suffix)
	with open(fname) as f:
		for line in f:
			fields = line.strip().split('/')
			if len(fields) > 0 and (snap is None or fields[-1] > snap):
				snap = fields[-1]
	if snap is None:
		fatal(options, "no snapshots listed in", fname)
	return snap
		
def do_backup_coroutine(section, options):
	directory = get_directory(section, options)
	name = section.get("OutputName", section.name)
	always_full = section.getboolean("AlwaysDoFull", False)
	
	do_full = options.full or always_full
	
	source_snapshot = find_latest_snapshot(section, directory, options)
	if do_full:
		stem = options.full_suffix if always_full else options.first_suffix
	else:
		stem = options.next_suffix
		shared_fname = os.path.join(directory, read_snapshots(section, options))
	
	latest_fname = os.path.join(directory, source_snapshot)
	
	output_basename = name + stem + options.output_suffix
	output_name = os.path.join(options.output, output_basename)
	if do_full:
		backup, backup_command = start_full_backup(section, latest_fname, options)
	else:
		backup, backup_command = start_incremental_backup(section, latest_fname, shared_fname, options)
		
	# should read a block from backup in case gpg & btrfs both ask questions
		
	encryption, encryption_command = start_encryption(backup, section, options)
	encrypted = encryption.stdout.read(options.blocking)
	
	output_tmp_name = output_name + section.get("TmpSuffix", ".tmp")
	md5_basename = name + stem + options.md5_suffix
	
	with open(os.path.join(options.output, md5_basename), "w") as md5_file:
		with open(output_tmp_name, "wb") as output_tmp:
			q = multiprocessing.Queue()
			worker = multiprocessing.Process(target=put_result, args=(functools.partial(read_write_md5, encrypted, encryption.stdout, output_tmp, options), q))
			worker.start()
			possible_unlink(output_name, options)
			verbose(options, "running backup in section", section.name, "from", source_snapshot, "to", output_name, "full?", do_full)
			yield
			verbose(options, "waiting for backup in section", section.name, "from", source_snapshot, "to", output_name, "full?", do_full)
			md5 = q.get()
			worker.join()
			flush(output_tmp)
			set_filemode(output_tmp, section, options)
		
		wait_command(backup, backup_command, options)
		if encryption_command:
			wait_command(encryption, encryption_command, options)
		
		print(md5 + " *" + output_basename, file=md5_file)
	
		flush(md5_file)
		set_filemode(md5_file, section, options)

	rename(output_tmp_name, output_name, options)
	yield md5_basename

def backup(config, sections, options):
	coroutines = []
	for section_name in config.sections():
		if len(sections) == 0 or section_name in sections:
			section = config[section_name]
			if not section.getboolean("active", True):
				verbose(options, "skipping", section_name, "as it is flagged as inactive")
			else:
				coroutines.append(do_backup_coroutine(section, options))
		else:
			verbose(options, "skipping section", section_name, "as not in", sections)
			
	md5files = run_coroutines(coroutines, options)

	if options.check_md5:
		cmd = [ "md5sum", "--check", "--strict", "--quiet"] + md5files
		print_command(cmd, options)
		subprocess.check_call(cmd, cwd=options.output)
	
def read_config(options):
	config = configparser.ConfigParser()
	with open(options.config) as f:
		config.read_file(f)
	dir = options.config_dir
	if dir:
		try:
			entries = os.listdir(dir)
		except OSError as e:
			if e.errno != errno.ENOENT:
				raise
		else:
			for f in entries:
				if f.endswith(options.config_dir_contents_suffix):
					c = os.path.join(dir, f)
					verbose(options, "additional config from", c)
					with open(c) as f:
						config.read_file(f)
	return config

def read_btrfs_coroutine(entry, stem, fname, options):
	snapshot_command = ["sudo", "/bin/sh", "-c", "cat && btrfs subvolume list -uso " + stem]
	snapshot_lister = subprocess.Popen(snapshot_command, stdin=subprocess.PIPE, stdout=subprocess.PIPE)
	
	if options.list_snapshots_only:
		yield
	else:
		fencrypted = os.path.join(options.read, entry)
		with open(fencrypted) as encrypted:
			verbose(options, options.decrypter, fencrypted)
			gpg = subprocess.Popen([options.decrypter], stdin=encrypted, stdout=subprocess.PIPE)
		decrypted = gpg.stdout.read(options.blocking)
		btrfs_cmd = ["sudo", "btrfs", "receive", stem]
		verbose(options, " ".join(btrfs_cmd))
		receive = subprocess.Popen(btrfs_cmd, stdin=subprocess.PIPE)
		receive.stdin.write(decrypted)
		worker = multiprocessing.Process(target=shutil.copyfileobj, args=(gpg.stdout, receive.stdin, options.blocking))
		worker.start()

		yield

		verbose(options, "waiting for", " ".join(btrfs_cmd))
		worker.join()
		receive.stdin.close()
		if gpg.wait() != 0:
			sys.exit(options.decrypter + " failed for " + fencrypted)
		if receive.wait() != 0:
			sys.exit(" ".join(btrfs_cmd) + " failed for " + fencrypted)
		verbose(options, "have", " ".join(btrfs_cmd), "for", fencrypted)
			
	snapshot_lister.stdin.close()	
	snapshots = os.path.join(options.read, stem + options.snapshots_suffix)
	with open(snapshots, "wb") as output:
		shutil.copyfileobj(snapshot_lister.stdout, output)
	if snapshot_lister.wait() != 0:
		fatal(options, " ".join(snapshot_command), "failed")
	verbose(options, " ".join(snapshot_command), ">", snapshots)
	
	yield

class ReadBtrfs:
	def __init__(self, entry, stem, fname, options):
		self._entry = entry
		self._stem = stem
		self._options = options
		self._fencrypted = os.path.join(options.read, entry)
		self._coroutine = read_md5_coroutine(entry, stem, fname, options)
		
	def start(self):
		subprocess.check_call(["sudo", "true"])
		if not self._options.list_snapshots_only:
			with open(self._fencrypted) as encrypted:
				verbose(self._options, self._options.decrypter, self._fencrypted)
				self._gpg = subprocess.Popen([self._options.decrypter], stdin=encrypted, stdout=subprocess.PIPE)
			decrypted = self._gpg.stdout.read(self._options.blocking)
			self._btrfs_cmd = ["sudo", "btrfs", "receive", self._stem]
			self._receive = subprocess.Popen(self._btrfs_cmd, stdin=subprocess.PIPE)
			self._receive.stdin.write(decrypted)
			self._worker = multiprocessing.Process(target=shutil.copyfileobj, args=(self._gpg.stdout, self._receive.stdin, self._options.blocking))
			self._worker.start()
			
		self._snapshot_command = ["sudo", "/bin/sh", "-c", "cat && btrfs subvolume list -uso " + self._stem]
		self._snapshot_lister = subprocess.Popen(self._snapshot_command, stdin=subprocess.PIPE, stdout=subprocess.PIPE)
			
		return self
			
	def finish(self):
		if not self._options.list_snapshots_only:
			self._worker.join()
			if self._receive.wait() != 0:
				sys.exit(" ".join(self.btrfs_cmd) + " failed for " + self._fencrypted)
			if self._gpg.wait() != 0:
				sys.exit(self._options.decrypter + " failed for " + self._fencrypted)
				
		self._snapshot_lister.stdin.close()	
		snapshots = os.path.join(self._options.read, self._stem + self._options.snapshots_suffix)
		with open(snapshots, "wb") as output:
			shutil.copyfileobj(self._snapshot_lister.stdout, output)
		if self._snapshot_lister.wait() != 0:
			fatal(self._options, " ".join(self._snapshot_command), "failed")
		verbose(self._options, " ".join(self._snapshot_command), ">", snapshots)

def read_btrfs(entry, stem, fname, options):
	return ReadBtrfs(entry, stem, fname, options).start()

def get_md5_from_file(md5_file):
	with open(md5_file) as input:
		line = input.readline()
		if not line:
			sys.exit("no MD5 line in " + md5_file)
		pos = line.find(" *")
		if pos == -1:
			sys.exit("no MD5 in " + md5_file)
		return line[:pos]
	
def copy_and_md5sum(src, dst, options):
	dumpmd5 = hashlib.md5()
	while True:
		buf = src.read(options.blocking)
		if len(buf) == 0:
			break
		dst.write(buf)
		dumpmd5.update(buf)
	dst.flush()
	return dumpmd5.hexdigest()

def read_md5_coroutine(entry, stem, fname, options):
	do_copy = not options.do_not_copy
	
	md5_file = os.path.join(options.read, fname + options.md5_suffix)
	md5 = get_md5_from_file(md5_file)
	
	new_snapshot = os.path.join(stem, entry)
		
	if do_copy:
		tmp = new_snapshot + ".tmp"
	else:
		tmp = "/dev/null"
		
	input_file = os.path.join(options.read, entry)
	with open(input_file, "rb") as input:
		with open(tmp, "wb") as output:
			q = multiprocessing.Queue()
			worker = multiprocessing.Process(target=put_result, args=(functools.partial(copy_and_md5sum, input, output, options), q))
			worker.start()
			verbose(options, "copy", input_file, "to", tmp)
			yield
			verbose(options, "waiting for copy result", input_file, "to", tmp)
			new_md5 = q.get()
			verbose(options, "have copy result", input_file, "to", tmp)
			worker.join()

	if new_md5 != md5:
		sys.exit("MD5 mismatch for %s (%s != %s)"  % (entry, md5, new_md5))
		
	if do_copy:
		with open(md5_file) as input:
			new_md5_file = os.path.join(stem, fname + options.md5_suffix)
			with open(new_md5_file, "w") as output:
				verbose(options, "cp", md5_file, new_md5_file)
				shutil.copyfileobj(input, output)
			
		verbose(options, "mv", tmp, new_snapshot)
		os.rename(tmp, new_snapshot)
		verbose(options, "finished copying", input_file, "to", tmp)
		
	yield

class ReadMD5:
	def __init__(self, entry, stem, fname, options):
		self._coroutine = read_md5_coroutine(entry, stem, fname, options)
		self._options = options
		
	def start(self):
		verbose(self._options, "ReadMD5", "before 1st next")
		next(self._coroutine)
		verbose(self._options, "ReadMD5", "after 1st next")
		return self
	
	def finish(self):
		verbose(self._options, "ReadMD5", "before 2nd next")
		next(self._coroutine)
		verbose(self._options, "ReadMD5", "after 2nd next")
		return
		entry = self._entry
		stem = self._stem
		fname = self._fname
		options = self._options
		
		md5_file = os.path.join(options.read, fname + options.md5_suffix)
		md5 = get_md5_from_file(md5_file)
		
		new_snapshot = os.path.join(stem, entry)
			
		tmp = new_snapshot + ".tmp"
		input_file = os.path.join(options.read, entry)
		with open(input_file, "rb") as input:
			with open(tmp, "wb") as output:
				verbose(options, "copying", input_file, "to", tmp)
				new_md5 = copy_and_md5sum(input, output, options)

		if new_md5 != md5:
			sys.exit("MD5 mismatch for %s (%s != %s)"  % (entry, md5, new_md5))
			
		with open(md5_file) as input:
			new_md5_file = os.path.join(stem, fname + options.md5_suffix)
			with open(new_md5_file, "w") as output:
				verbose(options, "cp", md5_file, new_md5_file)
				shutil.copyfileobj(input, output)
			
		verbose(options, "mv", tmp, new_snapshot)
		os.rename(tmp, new_snapshot)
			
def read_md5(entry, stem, fname, options):
	return ReadMD5(entry, stem, fname, options).start()
	md5_file = os.path.join(options.read, fname + options.md5_suffix)
	md5 = get_md5_from_file(md5_file)
	
	new_snapshot = os.path.join(stem, entry)
		
	tmp = new_snapshot + ".tmp"
	dumpmd5 = hashlib.md5()
	input_file = os.path.join(options.read, entry)
	with open(input_file, "rb") as input:
		with open(tmp, "wb") as output:
			verbose(options, "copying", input_file, "to", tmp)
			while True:
				buf = input.read(options.blocking)
				if len(buf) == 0:
					break
				output.write(buf)
				dumpmd5.update(buf)

	new_md5 = dumpmd5.hexdigest()
	if new_md5 != md5:
		sys.exit("MD5 mismatch for %s (%s != %s)"  % (entry, md5, new_md5))
		
	with open(md5_file) as input:
		new_md5_file = os.path.join(stem, stem + options.md5_suffix)
		with open(new_md5_file, "w") as output:
			verbose(options, "cp", md5_file, new_md5_file)
			shutil.copyfileobj(input, output)
		
	verbose(options, "mv", tmp, new_snapshot)
	os.rename(tmp, new_snapshot)

def read(options, sections):
	tags = [
		(options.first_suffix + options.output_suffix, read_btrfs_coroutine),
		(options.next_suffix + options.output_suffix, read_btrfs_coroutine),
		(options.full_suffix + options.output_suffix, read_md5_coroutine)
	]
	coroutines = []
	for entry in os.listdir(options.read):
		for tag, func in tags:
			if entry.endswith(tag):
				stem = entry[:-len(tag)]
				fname = entry[:-len(options.output_suffix,)]
				if len(sections) == 0 or stem in sections:
					coroutines.append(func(entry, stem, fname, options))
				break
			
	run_coroutines(coroutines, options)
		
def main():
	parser = optparse.OptionParser(usage="%prog [options] [--help] [sections]")
	parser.disable_interspersed_args()
	parser.add_option("-v", "--verbose", action="store_true", help="verbose")
	parser.add_option("--read", default=None, help="read snapshots from directory")
	parser.add_option("-n", "--no_update", action="store_true", help="don't update the record of last backup")
	parser.add_option("--btrfs_verbose", action="store_true", help="give verbose flag to btrfs")
	parser.add_option("-5", "--check_md5", action="store_true", help="check MD5 sums of generated files")
	parser.add_option("-0", "--full", action="store_true", help="do full backups")
	parser.add_option("--output", default=".", help="output directory [%default]")
	parser.add_option("-C", "--config", default="/etc/local/btrfs-snapshot-sender.conf", help="config file [%default]")
	parser.add_option("--config_dir", default="/etc/local/btrfs-snapshot-sender.d", help="directory of config files [%default]")
	parser.add_option("--config_dir_contents_suffix", default=".conf", help="suffix for each file in directory of config files [%default]")
	parser.add_option("--decrypter", default="gpg", help="program to decrypt stdin [%default]")
	parser.add_option("--list_snapshots_only", action="store_true", help="don't read backups, just list current snapshots")
	parser.add_option("--do_not_copy", action="store_true", help="don't copy full backups, just check MD5 sum")
	parser.add_option("--snapshots_suffix", default=".snapshots", help="file suffix for list of snapshots [%default]")
	parser.add_option("--first_suffix", default="+0", help="file suffix for base backup for incrementals [%default]")
	parser.add_option("--next_suffix", default="+n", help="file suffix for next backup for incrementals [%default]")
	parser.add_option("--full_suffix", default="+f", help="file suffix for backup for full backups [%default]")
	parser.add_option("--output_suffix", default=".btrfs", help="file suffix for all backups [%default]")
	parser.add_option("--md5_suffix", default=".md5", help="file suffix for MD5 checksums [%default]")
	parser.add_option("--blocking", type ='int', default=16 * 1024, help="read size [%default]")
	(options, sections) = parser.parse_args()
	
	if options.read:
		read(options, frozenset(sections))
	else:
		config = read_config(options)
		backup(config, frozenset(sections), options)

if __name__ == "__main__":
	main()
