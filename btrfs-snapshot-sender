#!/usr/bin/python3
# btrfs-snapshot-sender Copyright (c) 2014,2015 Stuart Pook (http://www.pook.it/)
# Use btrfs send to backup from existing snapshots. Can do incremental backups.
# vim: set shiftwidth=4 tabstop=4 noexpandtab copyindent preserveindent softtabstop=0 
#
# This program is free software: you can redistribute it and/or modify it under
# the terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful, but WITHOUT
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
# FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

# To use this program create a file on the backup medium called
# "btrfs-snapshot-sender.tag" containing a short unique tag for the
# backups on this medium, and a file
# "/etc/local/btrfs-snapshot-sender.conf" containing:
'''
[DEFAULT]
SnapshotRoot = /disks/data/snapshots
[music]
[photos]
'''
# This will find the most recent snapshot under /disks/data/snapshots/{music,photos}
# and back them up using btrfs send and gpg.
# You will have to read the code to find the other options that can go in the configuration file.

# Watch out for https://patchwork.kernel.org/patch/3258971/

import os
import re
import sys
import subprocess
import hashlib
import optparse
import configparser
import errno
import fnmatch
import shutil
import multiprocessing
import functools
import io
import shlex

def myname():
	return os.path.basename(sys.argv[0])

def verbose(options, *args):
	if options.verbose:
		print(myname() + ":", *args, file=sys.stderr)

def fatal(options, *args):
	print(myname() + ": fatal error:", *args, file=sys.stderr)
	sys.exit(7)

def flush(f):
	f.flush()
	os.fsync(f.fileno())

def rename(src, dst, options):
	verbose(options, "mv", src, dst)
	os.rename(src, dst)

def run_coroutines(coroutines, options):
	verbose(options, "no questions phase")
	for coroutine in coroutines:
		next(coroutine)
	verbose(options, "questions phase")
	for coroutine in coroutines:
		next(coroutine)
	verbose(options, "wait phase")
	r = []
	for coroutine in coroutines:
		r.append(next(coroutine))
	return r

def scan_snapshot_directory(directory, section, options):
	glob = section.get("SnapshotGlob", "[!.]*[!#~]")
	latest = None
	for entry in os.listdir(directory):
		if fnmatch.fnmatch(entry, glob) and (not latest or entry > latest):
			latest = entry

	if not latest:
		fatal(options, "no snapshots in", directory)
	return latest

def print_command(cmd, options):
	verbose(options, "run", " ".join(shlex.quote(c) for c in cmd))
	return cmd

def put_result(f, q):
	q.put(f())

def start_encryption(section, options):
	gpg_command = section.get("Filter", "/bin/cat")
	gpg = shlex.split(gpg_command)
	for i in range(100):
		extra = section.get("FilterArgument%02d" % i, None)
		if extra is not None:
			gpg.append(extra)
	print_command(gpg, options)
	return subprocess.Popen(gpg, stdout=subprocess.PIPE, stdin=subprocess.PIPE), gpg

def get_btrfs_command(section, options):
	return shlex.split(section.get("BtrfsSend", options.sudo + " btrfs send"))

def start_full_backup(section, snapshot, options):
	cmd = get_btrfs_command(section, options)
	if options.btrfs_verbose:
		cmd.append("-v")
	cmd.append(snapshot)
	print_command(cmd, options)
	return subprocess.Popen(cmd, stdout=subprocess.PIPE), cmd

def start_incremental_backup(section, latest_fname, in_use_fname, options):
	cmd = get_btrfs_command(section, options)
	if options.btrfs_verbose:
		cmd.append("-v")
	cmd.extend(["-p", in_use_fname])
	cmd.append(latest_fname)
	print_command(cmd, options)
	return subprocess.Popen(cmd, stdout=subprocess.PIPE), cmd

def read_write_md5(buf, input, output, output_fname, options):
	dumpmd5 = hashlib.md5()
	while True:
		try:
			output.write(buf)
		except OSError as ex:
			fatal(options, "OSError writing on %s: %s" % (output_fname, ex))
		dumpmd5.update(buf)
		buf = input.read(options.blocking)
		if len(buf) == 0:
			break
	output.flush() # in case we are in a subprocess
	return dumpmd5.hexdigest()

def read_write(buf, input, output, options):
	while True:
		output.write(buf)
		buf = input.read(options.blocking)
		if len(buf) == 0:
			break
	output.flush() # in case we are in a subprocess

def wait_check(p, cmd, options, *args):
	if p.wait():
		fatal(options, "failed:", " ".join(shlex.quote(c) for c in cmd), *args)

def set_filemode(file, section, options):
	u = section.get("OutputFileMode", None)
	if u:
		v = int(u, 8)
#		verbose(options, "fchmod", "0%o" % v, file.fileno())
		os.fchmod(file.fileno(), v)

def get_directory(section, options):
	snapshots_key = "Snapshots"
	directory = section.get(snapshots_key, None)
	if directory:
		return directory
	snapshotroot_key = "SnapshotRoot"
	root = section.get(snapshotroot_key, None)
	if root is None:
		fatal(options, "a", snapshots_key, "or", snapshotroot_key, "attribute is required for section", section.name)
	return os.path.join(root, section.name)

def possible_unlink(output_name, options):
	try:
		os.unlink(output_name)
		verbose(options, "removed", output_name)
	except FileNotFoundError as ex:
		if ex.errno != errno.ENOENT:
			raise

def find_latest_snapshot(section, directory, options):
	glob = section.get("SnapshotGlob", "[!.]*[!#~]")
	latest = None
	for entry in os.listdir(directory):
		if fnmatch.fnmatch(entry, glob):
			if not latest or entry > latest:
				latest = entry
	if not latest:
		fatal(options, "no snapshots in", directory)
	return latest

def read_snapshots(section, options):
	snap = None
	fname = os.path.join(options.output, section.name + section.get("SnapListSuffix", options.snapshots_suffix))
	with open(fname) as f:
		for line in f:
			fields = line.strip().split('/')
			if len(fields) > 0 and (snap is None or fields[-1] > snap):
				snap = fields[-1]
	if snap is None:
		fatal(options, "no snapshots listed in", fname)
	return snap

def copy_file_objs(data, src, dst, options):
	dst.write(data)
	shutil.copyfileobj(src, dst)
	dst.flush()

def join_check(process, options, *args):
	process.join()
	if process.exitcode != 0:
		fatal(options, "subprocess failed (" + str(process.exitcode) + "):", *args)

def do_backup_coroutine(section, options):
	directory = get_directory(section, options)
	name = section.get("OutputName", section.name)
	always_full = section.getboolean("AlwaysDoFull", False)
	do_full = options.full or always_full
	source_snapshot = find_latest_snapshot(section, directory, options)

	yield

	if do_full:
		stem = options.full_suffix if always_full else options.first_suffix
	else:
		stem = options.next_suffix
		shared_fname = os.path.join(directory, read_snapshots(section, options))

	latest_fname = os.path.join(directory, source_snapshot)

	if do_full:
		backuper, backup_command = start_full_backup(section, latest_fname, options)
	else:
		backuper, backup_command = start_incremental_backup(section, latest_fname, shared_fname, options)

	data = backuper.stdout.read(options.blocking) # make sure the backup command has finished asking any questions

	encryption, encryption_command = start_encryption(section, options)

	backup2encryption = multiprocessing.Process(target=copy_file_objs, args=(data, backuper.stdout, encryption.stdin, options), daemon=True)
	backup2encryption.start()
	encryption.stdin.close()
	backuper.stdout.close()

	encrypted = encryption.stdout.read(options.blocking) # make sure the encryption command has finished asking any questions

	output_basename = name + stem + options.output_suffix
	output_name = os.path.join(options.output, output_basename)
	output_tmp_name = output_name + section.get("TmpSuffix", ".tmp")
	md5_basename = name + stem + options.md5_suffix

	with open(os.path.join(options.output, md5_basename), "w") as md5_file:
		with open(output_tmp_name, "wb") as output_tmp:
			q = multiprocessing.Queue()
			gpg2file = multiprocessing.Process(target=put_result, args=(functools.partial(read_write_md5, encrypted, encryption.stdout, output_tmp, output_tmp_name, options), q), daemon=True)
			gpg2file.start()
			encryption.stdout.close()
			possible_unlink(output_name, options)
			verbose(options, "running backup in section", section.name, "from", source_snapshot, "to", output_name, "full" if do_full else "incremental")
			yield
			verbose(options, "waiting for backup in section", section.name)
			join_check(backup2encryption, options, "backup2encryption")
			join_check(gpg2file, options, "read, md5 & write")
			set_filemode(output_tmp, section, options)
			os.fsync(output_tmp.fileno())

		wait_check(backuper, backup_command, options, section.name)
		wait_check(encryption, encryption_command, options, section.name)
		md5 = q.get()

		print(md5 + " *" + output_basename, file=md5_file)

		flush(md5_file)
		set_filemode(md5_file, section, options)

	rename(output_tmp_name, output_name, options)
	verbose(options, "finished backup in section", section.name)
	yield md5_basename

def backup(config, sections, options):
	coroutines = []
	for section_name in config.sections():
		if len(sections) == 0 or section_name in sections:
			section = config[section_name]
			if not section.getboolean("active", True):
				verbose(options, "skipping", section_name, "as it is flagged as inactive")
			else:
				coroutines.append(do_backup_coroutine(section, options))
		else:
			verbose(options, "skipping section", section_name, "as not in", sections)

	md5files = run_coroutines(coroutines, options)

	if options.check_md5:
		cmd = [ "md5sum", "--check", "--strict", "--quiet"] + md5files
		print_command(["cd", options.output, ';'] + cmd, options)
		subprocess.check_call(cmd, cwd=options.output)

def read_config(options):
	config = configparser.ConfigParser()
	with open(options.config) as f:
		config.read_file(f)
	dir = options.config_dir
	if dir:
		try:
			entries = os.listdir(dir)
		except OSError as e:
			if e.errno != errno.ENOENT:
				raise
		else:
			for f in entries:
				if f.endswith(options.config_dir_contents_suffix):
					c = os.path.join(dir, f)
					verbose(options, "additional config from", c)
					with open(c) as f:
						config.read_file(f)
	return config

def get_snapshot_from_btrfs_receive(stdout, btrfs_cmd, options):
#	c = os.read(subprocess.stdout.fileno(), 1)
#	verbose(options, '"' + " ".join(btrfs_cmd) + '"', "gave me", c)
	info = stdout.readline()
	if len(info) == 0:
		fatal(options, "nothing read from", " ".join(btrfs_cmd))
	m = re.match(r"^At subvol (\S+)$", info.rstrip())
	if m:
		snapshot = m.group(1)
	else:
		fatal(options, "bad output from", " ".join(btrfs_cmd), ":", info, stdout.read())
	info2 = stdout.readline()
	if len(info2) != 0:
		fatal(options, "too much output from", " ".join(btrfs_cmd), ":", info, info2, stdout.read())
	return snapshot

def quote(arg, options):
	return shlex.quote(arg)

def make_waitable_command(cmd, options):
	return [options.sudo, "sh", "-c", "echo foo && " + cmd]

def read_btrfs_coroutine(entry, stem, fname, options):
	verbose(options, "read_btrfs_coroutine no questions phase")
	md5_file = os.path.join(options.read, fname + options.md5_suffix)
	md5 = get_md5_from_file(md5_file)
	full_stem = os.path.join(options.output, stem)
	yield
	verbose(options, "read_btrfs_coroutine questions phase")
	snapshot_lister_command = "btrfs subvolume list -uRro " + quote(full_stem, options)
	snapshot_command = make_waitable_command("cat && " + snapshot_lister_command, options)
	snapshot_lister = subprocess.Popen(snapshot_command, stdin=subprocess.PIPE, stdout=subprocess.PIPE, universal_newlines=True)
	snapshot_lister.stdout.readline() # make sure sudo has finished asking any questions

	snapshots = os.path.join(options.read, stem + options.snapshots_suffix)
	snapshots_tmp = snapshots + ".tmp"
	with open(snapshots_tmp, "w") as snap_file:
		if options.list_snapshots_only:
				snapshot = False
				yield
				verbose(options, "read_btrfs_coroutine wait phase")
		else:
				fencrypted = os.path.join(options.read, entry)
				verbose(options, options.decrypter, fencrypted)
				gpg = subprocess.Popen([options.decrypter], stdin=subprocess.PIPE, stdout=subprocess.PIPE, shell=True)

				with open(fencrypted, "rb") as encrypted:
						q = multiprocessing.Queue()
						data_checker = multiprocessing.Process(target=put_result, args=(functools.partial(read_write_md5, b"", encrypted, gpg.stdin, options), q), daemon=True)
						data_checker.start()

				gpg.stdin.close()
				decrypted = gpg.stdout.read(options.blocking) # make sure gpg has finished asking any questions

				btrfs_cmd = make_waitable_command("btrfs receive " + quote(full_stem, options), options)

				verbose(options, "starting", '"' + " ".join(btrfs_cmd) + '"')
				receive = subprocess.Popen(btrfs_cmd, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
				gpg2receive = multiprocessing.Process(target=read_write, args=(decrypted, gpg.stdout, receive.stdin, options), daemon=True)
				gpg2receive.start()
				receive.stdin.close()
				receive_as_text = io.TextIOWrapper(receive.stdout)
				receive_as_text.readline() # make sure sudo has finished asking any questions

				yield

				verbose(options, "waiting for", '"' + " ".join(btrfs_cmd) + '"')
				snapshot = get_snapshot_from_btrfs_receive(receive_as_text, btrfs_cmd, options)
				wait_check(receive, btrfs_cmd, options, "for", stem)
				wait_check(gpg, [options.decrypter], options, "for", stem)
				join_check(gpg2receive, options, "subprocess to copy from gpg to btrfs receive failed for", stem)
				join_check(data_checker, options, "read", fencrypted, "md5 and write")
				new_md5 = q.get()
				if md5 != new_md5:
						fatal(options, "md5", new_md5, "of data read from", fencrypted, "does not match md5", md5, "in", md5_file)

				verbose(options, '"' + " ".join(btrfs_cmd) + '"', "imported", snapshot, "from", fencrypted)

		snapshot_lister.stdin.close()
		found = not snapshot
		for line in snapshot_lister.stdout:
				found = found or line.strip().endswith(snapshot)
				print(line, end="", file=snap_file)
#		shutil.copyfileobj(snapshot_lister.stdout, output)
	if not options.list_snapshots_only:
		wait_check(snapshot_lister, snapshot_command, options, fencrypted)
	os.rename(snapshots_tmp, snapshots)
	if not found:
		fatal(options, "new snapshot", snapshot, "not found in list of snapshots given by", snapshot_lister_command)
	verbose(options, " ".join(snapshot_command), ">", snapshots)

	yield

def get_md5_from_file(md5_file):
	with open(md5_file) as input:
		line = input.readline()
		if not line:
			sys.exit("no MD5 line in " + md5_file)
		pos = line.find(" *")
		if pos == -1:
			sys.exit("no MD5 in " + md5_file)
		return line[:pos]

def read_md5_coroutine(entry, stem, fname, options):
	verbose(options, "read_md5_coroutine no questions phase")
	if options.list_snapshots_only:
		yield
		verbose(options, "read_md5_coroutine questions phase")
		yield
		verbose(options, "read_md5_coroutine wait phase")
	else:
		do_copy = not options.do_not_copy

		md5_file = os.path.join(options.read, fname + options.md5_suffix)
		md5 = get_md5_from_file(md5_file)

		new_snapshot = os.path.join(options.output, stem, entry)

		tmp = new_snapshot + ".tmp" if do_copy else "/dev/null"

		input_file = os.path.join(options.read, entry)
		with open(input_file, "rb") as input:
			with open(tmp, "wb") as output:
				q = multiprocessing.Queue()
				worker = multiprocessing.Process(target=put_result, args=(functools.partial(read_write_md5, b"", input, output, options), q), daemon=True)
				worker.start()
				verbose(options, "started copy", input_file, "to", tmp)
				yield
				yield
				verbose(options, "waiting for copy", input_file, "to", tmp)
				join_check(worker, options, "read, write & md5")
				new_md5 = q.get()
				verbose(options, "finished copy", input_file, "to", tmp)

		if new_md5 != md5:
			sys.exit("MD5 mismatch for %s (%s != %s)" % (entry, md5, new_md5))

		if do_copy:
			with open(md5_file) as input:
				new_md5_file = os.path.join(options.output, stem, fname + options.md5_suffix)
				with open(new_md5_file, "w") as output:
					verbose(options, "cp", md5_file, new_md5_file)
					shutil.copyfileobj(input, output)

			verbose(options, "mv", tmp, new_snapshot)
			os.rename(tmp, new_snapshot)
			verbose(options, "finished copying", input_file, "to", new_snapshot)

	yield
	verbose(options, "read_md5_coroutine done")

def read(options, sections):
	tags = [
		(options.first_suffix + options.output_suffix, read_btrfs_coroutine),
		(options.next_suffix + options.output_suffix, read_btrfs_coroutine),
		(options.full_suffix + options.output_suffix, read_md5_coroutine)
	]
	coroutines = []
	for entry in os.listdir(options.read):
		for tag, func in tags:
			if entry.endswith(tag):
				stem = entry[:-len(tag)]
				fname = entry[:-len(options.output_suffix,)]
				if len(sections) == 0 or stem in sections:
					coroutines.append(func(entry, stem, fname, options))
				break

	run_coroutines(coroutines, options)

def main():
	parser = optparse.OptionParser(usage="%prog [options] [--help] [sections]")
	parser.disable_interspersed_args()
	parser.add_option("-v", "--verbose", action="store_true", help="verbose")
	parser.add_option("--read", default=None, help="read snapshots from directory")
	parser.add_option("--btrfs_verbose", action="store_true", help="give verbose flag to btrfs")
	parser.add_option("-5", "--check_md5", action="store_true", help="check MD5 sums of generated files")
	parser.add_option("-0", "--full", action="store_true", help="do full backups")
	parser.add_option("--output", default="", help="output directory [%default]")
	parser.add_option("-C", "--config", default="/etc/local/btrfs-snapshot-sender.conf", help="config file [%default]")
	parser.add_option("--config_dir", default="/etc/local/btrfs-snapshot-sender.d", help="directory of config files [%default]")
	parser.add_option("--config_dir_contents_suffix", default=".conf", help="suffix for each file in directory of config files [%default]")
	parser.add_option("--decrypter", default="gpg", help="program to decrypt stdin [%default]")
	parser.add_option("--list_snapshots_only", action="store_true", help="don't read backups, just update list of current snapshots")
	parser.add_option("--do_not_copy", action="store_true", help="don't copy full backups, just check MD5 sum")
	parser.add_option("--snapshots_suffix", default=".snapshots", help="file suffix for list of snapshots [%default]")
	parser.add_option("--first_suffix", default="+0", help="file suffix for base backup for incrementals [%default]")
	parser.add_option("--next_suffix", default="+n", help="file suffix for next backup for incrementals [%default]")
	parser.add_option("--full_suffix", default="+f", help="file suffix for backup for full backups [%default]")
	parser.add_option("--output_suffix", default=".btrfs.gpg", help="file suffix for all backups [%default]")
	parser.add_option("--md5_suffix", default=".md5", help="file suffix for MD5 checksums [%default]")
	parser.add_option("--sudo", default="sudo", help="sudo command [%default]")
	parser.add_option("--blocking", type ='int', default=16 * 1024, help="read size [%default]")
	(options, sections) = parser.parse_args()

	if options.read:
		read(options, frozenset(sections))
	else:
		config = read_config(options)
		backup(config, frozenset(sections), options)

if __name__ == "__main__":
	main()
